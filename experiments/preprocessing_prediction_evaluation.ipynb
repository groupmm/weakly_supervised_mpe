{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60731303",
   "metadata": {},
   "source": [
    "# Data Preprocessing, Model Loading, Prediction, Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf8b52",
   "metadata": {},
   "source": [
    "This notebook shows how to preprocess audio files, load a trained model, how to predict pitches and evaluate the estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5dd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "basepath = os.path.dirname(os.path.abspath('.'))\n",
    "sys.path.append(basepath)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import libfmp\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "import torchinfo\n",
    "\n",
    "import libdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b812081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU / GPU \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a4b92",
   "metadata": {},
   "source": [
    "## 1. Load and preprocess audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08af84ed",
   "metadata": {},
   "source": [
    "### Load audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce89093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 22050\n",
    "\n",
    "audio_folder = os.path.join(basepath, 'data', 'Schubert_Winterreise', '01_RawData', 'audio_wav')\n",
    "fn_audio = 'Schubert_D911-23_SC06.wav'\n",
    "\n",
    "# Load audio\n",
    "path_audio = os.path.join(audio_folder, fn_audio)\n",
    "f_audio, fs_load = librosa.load(path_audio, sr=fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "libfmp.b.plot_signal(f_audio, Fs=fs_load)\n",
    "ipd.display(ipd.Audio(data=f_audio, rate=fs_load))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f735f",
   "metadata": {},
   "source": [
    "### Compute HCQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363bfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HCQT parameters\n",
    "bins_per_semitone = 3\n",
    "hcqt_config = {\n",
    "    'fs': fs,\n",
    "    'fmin': librosa.note_to_hz('C1'),  # MIDI pitch 24\n",
    "    'fs_hcqt_target': 50,\n",
    "    'bins_per_octave': 12 * bins_per_semitone,\n",
    "    'num_octaves': 6,\n",
    "    'num_harmonics': 5,\n",
    "    'num_subharmonics': 1,\n",
    "    'center_bins': True,\n",
    "}\n",
    "\n",
    "# Compute HCQT\n",
    "f_hcqt, fs_hcqt, hopsize_cqt = libdl.data_preprocessing.compute_efficient_hcqt(f_audio, **hcqt_config);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fc604e",
   "metadata": {},
   "source": [
    "### Visualize first harmonic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc99ad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix_with_ticks(data, title, bins_per_semitone=bins_per_semitone, \n",
    "                           hcqt_config=hcqt_config, fs_hqct=fs_hcqt, pitches=True, **kwargs):\n",
    "    vis_start_sec = 25\n",
    "    vis_stop_sec = 50\n",
    "    vis_step_sec = 5\n",
    "    \n",
    "    n_bins = bins_per_semitone*12*hcqt_config[\"num_octaves\"]\n",
    "\n",
    "    plt.rcParams.update({'font.size': 11})\n",
    "    fig, ax = plt.subplots(1, 2, gridspec_kw={'width_ratios': [1, 0.05]}, figsize=(10, 3.5))\n",
    "    im = libfmp.b.plot_matrix(data[:, int(vis_start_sec*fs_hcqt):int(vis_stop_sec*fs_hcqt)], \n",
    "                              Fs=fs_hcqt, ax=ax, cmap='gray_r', ylabel='MIDI pitch', **kwargs)\n",
    "    \n",
    "    if pitches:\n",
    "        ax[0].set_yticks(np.arange(0, 73, 12))\n",
    "        ax[0].set_yticklabels([str(24+12*octave) for octave in range(0, hcqt_config[\"num_octaves\"]+1)])\n",
    "    else:\n",
    "        ax[0].set_yticks(np.arange(1, n_bins+13, 12*bins_per_semitone))\n",
    "        ax[0].set_yticklabels([str(24+12*octave) for octave in range(0, hcqt_config[\"num_octaves\"]+1)])\n",
    "    ax[0].set_xticks(np.arange(0, (vis_stop_sec-vis_start_sec)+vis_step_sec, vis_step_sec))\n",
    "    ax[0].set_xticklabels(np.arange(vis_start_sec, vis_stop_sec+vis_step_sec, vis_step_sec))\n",
    "    ax[0].set_title(title)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef88599",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix_with_ticks(data=np.log(1+10*np.abs(f_hcqt[:, :, 1])), title='Harmonic 1 (fundamental)', pitches=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a932d1",
   "metadata": {},
   "source": [
    "## 2. Specify and load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986bfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_models = os.path.join(basepath, 'experiments', 'models')\n",
    "\n",
    "# fn_model = '02_schubert_baseline_ae.pt'\n",
    "# fn_model = '03_schubert_baseline_sup.pt'  \n",
    "# fn_model = '04_schubert_cva.pt'\n",
    "# fn_model = '05_schubert_cva_ov.pt'\n",
    "# fn_model = '06_schubert_cva_b.pt'\n",
    "fn_model = '07_schubert_cva_ov_b.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567244d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "num_octaves_inp = 6\n",
    "num_output_bins, min_pitch = 72, 24\n",
    "model_params = {\n",
    "    'n_chan_input': 6,\n",
    "    'n_chan_layers': [20, 20, 10, 1],\n",
    "    'n_bins_in': num_octaves_inp * 12 * 3,\n",
    "    'n_bins_out': num_output_bins,\n",
    "    'a_lrelu': 0.3,\n",
    "    'p_dropout': 0.2\n",
    "}\n",
    "\n",
    "if fn_model == '03_schubert_baseline_sup.pt':\n",
    "    # Model without final sigmoid activation; only for 03_schubert_baseline_sup \n",
    "    model = libdl.nn_models.basic_cnn_segm_logit(**model_params)\n",
    "else:\n",
    "    # Model with final sigmoid activation\n",
    "    model = libdl.nn_models.basic_cnn_segm_sigmoid(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8597b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model.load_state_dict(torch.load(os.path.join(dir_models, fn_model), map_location=device))\n",
    "\n",
    "model.to(device)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchinfo.summary(model, input_size=(1, 6, 574, 216), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9bc3bd7",
   "metadata": {},
   "source": [
    "## 3. Predict pitches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d93f3",
   "metadata": {},
   "source": [
    "### Create dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_params = {\n",
    "    'context': 75,\n",
    "    'compression': 10   # log-compression applied to HCQT\n",
    "}\n",
    "\n",
    "half_context = test_dataset_params['context'] // 2\n",
    "\n",
    "inputs = np.transpose(f_hcqt, (2, 1, 0))\n",
    "\n",
    "# Pad input in order to account for context frames\n",
    "inputs_context = torch.from_numpy(np.pad(inputs, ((0, 0), (half_context, half_context+1), (0, 0))))\n",
    "\n",
    "# Create dummy targets for dataset object\n",
    "targets_context = torch.zeros(inputs_context.shape[1], num_output_bins)\n",
    "\n",
    "test_dataset_params['seglength'] = inputs.shape[1]  # dataset will then contain only 1 segment which includes all frames\n",
    "test_dataset_params['stride'] = inputs.shape[1]\n",
    "\n",
    "test_set = libdl.data_loaders.dataset_context_segm(inputs_context, targets_context, test_dataset_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608f412",
   "metadata": {},
   "source": [
    "### Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch, _ = test_set[0]\n",
    "\n",
    "# Batch format\n",
    "test_batch = test_batch.unsqueeze(dim=0).to(device)\n",
    "\n",
    "# Predict\n",
    "y_pred = model(test_batch)\n",
    "\n",
    "# Apply sigmoid activation if not contained as last layer in model\n",
    "if model.__class__ == libdl.nn_models.basic_cnns_mctc.basic_cnn_segm_logit:\n",
    "    y_pred = torch.sigmoid(y_pred)\n",
    "\n",
    "# Convert prediction to Numpy array\n",
    "pred = y_pred.to('cpu').detach().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bec75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_matrix_with_ticks(data=pred.T, title='Pitch prediction', pitches=True, clim=[0.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ec0b42",
   "metadata": {},
   "source": [
    "### (Visualize predictions + overtone model / bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfc9dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overtone_model(pred):\n",
    "    shifts = [12, 19, 24, 28, 31, 34, 36, 38, 40]\n",
    "    strengths = 0.9 ** np.array(shifts)\n",
    "\n",
    "    w_overtones = torch.clone(pred)\n",
    "    for shift, strength in zip(shifts, strengths):\n",
    "        w_overtones[:, :, shift:] += strength * pred[:, :, :-shift]\n",
    "    return torch.clip(w_overtones, 0.0, 1.0)\n",
    "\n",
    "pred_ov = overtone_model(y_pred.squeeze(dim=1))\n",
    "pred_ov_np = pred_ov.to('cpu').detach().squeeze().numpy()\n",
    "\n",
    "plot_matrix_with_ticks(data=pred_ov_np.T, title='Pitch prediction + Ov', pitches=True, clim=[0.0, 1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e444e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = 0.2\n",
    "pred_ov_b = torch.clip(pred_ov + bias, 0.0, 1.0).to('cpu').detach().squeeze().numpy()\n",
    "\n",
    "plot_matrix_with_ticks(data=pred_ov_b.T, title='Pitch prediction + Ov + B', pitches=True, clim=[0.0, 1.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f4252",
   "metadata": {},
   "source": [
    "## 4. Load and convert annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c359135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_folder = os.path.join(basepath, 'data', 'Schubert_Winterreise', '02_Annotations', 'ann_audio_note')\n",
    "fn_annot = os.path.join(annot_folder, fn_audio[:-4]+'.csv')\n",
    "\n",
    "if os.path.exists(fn_annot):\n",
    "    df = pd.read_csv(fn_annot, sep=';', skiprows=1, header=None)\n",
    "    note_events = df.to_numpy()[:, :3]\n",
    "\n",
    "    f_annot_pitch = libdl.data_preprocessing.compute_annotation_array_nooverlap(note_events, f_hcqt, fs_hcqt, \n",
    "                                                                               annot_type='pitch', shorten=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889b8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fn_annot):\n",
    "    plot_matrix_with_ticks(data=f_annot_pitch[24:97], title='Pitch annotations', pitches=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c2ac1",
   "metadata": {},
   "source": [
    "## 5. Multi-pitch evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c213c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_measures = ['precision', 'recall', 'f_measure', 'cosine_sim', 'binary_crossentropy', 'euclidean_distance',\n",
    "                 'binary_accuracy', 'soft_accuracy', 'accum_energy', 'roc_auc_measure', 'average_precision_score']\n",
    "\n",
    "eval_thresh = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2062507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thresholding\n",
    "pred_th = (pred > eval_thresh).astype(float)\n",
    "\n",
    "plot_matrix_with_ticks(data=pred_th.T, title=f'Pitch prediction after thresholding (tau={eval_thresh})', pitches=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79062228",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fn_annot):\n",
    "    # Calculate metrics\n",
    "    targ = np.transpose(f_annot_pitch, (1, 0))[:, min_pitch:(min_pitch+num_output_bins)]\n",
    "\n",
    "    eval_dict = libdl.metrics.calculate_eval_measures(targ, pred, measures=eval_measures, threshold=eval_thresh, save_roc_plot=False)\n",
    "    eval_numbers = np.fromiter(eval_dict.values(), dtype=float)\n",
    "\n",
    "    metrics_mpe = libdl.metrics.calculate_mpe_measures_mireval(targ, pred, threshold=eval_thresh, min_pitch=min_pitch)\n",
    "    mireval_measures = [key for key in metrics_mpe.keys()]\n",
    "    mireval_numbers = np.fromiter(metrics_mpe.values(), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc57b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(fn_annot):\n",
    "    for i, meas_name in enumerate(eval_measures):\n",
    "        print(f'{meas_name:<30} {eval_numbers[i]}')\n",
    "\n",
    "    print('')\n",
    "\n",
    "    for i, meas_name in enumerate(mireval_measures):\n",
    "        print(f'{meas_name:<30} {mireval_numbers[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
